from fastapi import FastAPI, UploadFile, File, Form, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import whisper
import os
import time
from typing import List, Dict, Any, Optional
import tempfile
import numpy as np
import ffmpeg

# é‡å†™ Whisper çš„ load_audio å‡½æ•°ï¼Œä½¿ç”¨çº¯ Python å¤„ç† WAV æ–‡ä»¶
def custom_load_audio(file: str, sr: int = 16000):
    """ä½¿ç”¨çº¯ Python å¤„ç† WAV æ–‡ä»¶ï¼Œé¿å…ä¾èµ–å¤–éƒ¨ FFmpeg å‘½ä»¤"""
    print(f"ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰ load_audio å‡½æ•°å¤„ç†æ–‡ä»¶: {file}")
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        ext = os.path.splitext(file)[1].lower()
        
        if ext == '.wav':
            print(f"ğŸ“¦ ç›´æ¥å¤„ç† WAV æ–‡ä»¶")
            
            # ä½¿ç”¨ wave æ¨¡å—ç›´æ¥è¯»å– WAV æ–‡ä»¶
            import wave
            
            with wave.open(file, 'rb') as wf:
                # è·å–éŸ³é¢‘ä¿¡æ¯
                channels = wf.getnchannels()
                sample_width = wf.getsampwidth()
                original_sr = wf.getframerate()
                n_frames = wf.getnframes()
                
                print(f"   WAV ä¿¡æ¯: å£°é“={channels}, ä½æ·±={sample_width*8}bit, é‡‡æ ·ç‡={original_sr}, å¸§æ•°={n_frames}")
                
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = wf.readframes(n_frames)
                
                # è½¬æ¢ä¸º numpy æ•°ç»„
                if sample_width == 2:
                    # 16ä½ PCM
                    audio = np.frombuffer(data, np.int16)
                elif sample_width == 4:
                    # 32ä½ PCM
                    audio = np.frombuffer(data, np.int32)
                else:
                    # 8ä½ PCM
                    audio = np.frombuffer(data, np.uint8)
                    audio = audio.astype(np.float32) - 128  # è½¬æ¢ä¸º [-1, 1] èŒƒå›´
                
                # è½¬æ¢ä¸ºå•å£°é“
                if channels > 1:
                    print(f"   è½¬æ¢ä¸ºå•å£°é“")
                    audio = audio.reshape(-1, channels).mean(axis=1)
                
                # å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´
                if sample_width == 2:
                    audio = audio.astype(np.float32) / 32768.0
                elif sample_width == 4:
                    audio = audio.astype(np.float32) / 2147483648.0
                
                # é‡é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if original_sr != sr:
                    print(f"   é‡é‡‡æ ·: {original_sr}Hz â†’ {sr}Hz")
                    # ä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
                    from scipy import signal
                    audio = signal.resample(audio, int(len(audio) * sr / original_sr))
                
                print(f"âœ… WAV å¤„ç†æˆåŠŸï¼Œæ ·æœ¬æ•°é‡: {len(audio)}")
                return audio
        else:
            # å¯¹äºå…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨ wave æ¨¡å—æŠ›å‡ºæ˜ç¡®çš„é”™è¯¯
            print(f"âŒ ä»…æ”¯æŒ WAV æ ¼å¼ï¼Œä¸æ”¯æŒ {ext} æ ¼å¼")
            raise RuntimeError(f"Only WAV format is supported, got {ext}")
    except wave.Error as e:
        print(f"âŒ WAV æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
        raise RuntimeError(f"Failed to load WAV audio: {e}") from e
    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¤„ç†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        raise

# æ›¿æ¢ Whisper åº“çš„é»˜è®¤ load_audio å‡½æ•°
whisper.audio.load_audio = custom_load_audio
print("âœ… å·²æ›¿æ¢ Whisper çš„ load_audio å‡½æ•°ï¼Œä½¿ç”¨çº¯ Python å¤„ç† WAV éŸ³é¢‘")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Whisper Python API",
    version="2.0.0",
    description="åŸºäº Whisper çš„è¯­éŸ³è¯†åˆ« APIï¼Œæ”¯æŒ GPU åŠ é€Ÿ"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥è®¾ç½®å…·ä½“çš„æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ¨¡å‹ç¼“å­˜ï¼Œé¿å…é‡å¤åŠ è½½
model_cache = {}

# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = [
    "tiny",
    "base",
    "small",
    "medium",
    "large"
]

# æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
SUPPORTED_LANGUAGES = [
    "zh", "en", "ja", "ko", "fr", "de", "es", "ru", "it", "pt",
    "nl", "pl", "tr", "ar", "hi", "id", "ms", "th", "vi", "fil"
]

# åŠ è½½æ¨¡å‹çš„è¾…åŠ©å‡½æ•°
def load_model(model_name: str):
    """åŠ è½½æ¨¡å‹ï¼Œå¦‚æœå·²åœ¨ç¼“å­˜ä¸­åˆ™ç›´æ¥è¿”å›"""
    if model_name in model_cache:
        print(f"ğŸ“¦ ä»ç¼“å­˜åŠ è½½æ¨¡å‹: {model_name}")
        return model_cache[model_name]
    
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
    start_time = time.time()
    
    # åŠ è½½æ¨¡å‹ï¼Œè‡ªåŠ¨ä½¿ç”¨GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    model = whisper.load_model(model_name)
    
    load_time = time.time() - start_time
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}s")
    
    # å­˜å…¥ç¼“å­˜
    model_cache[model_name] = model
    return model

# éŸ³é¢‘è½¬æ–‡æœ¬æ ¸å¿ƒå‡½æ•°
def transcribe_audio(file_path: str, options: Dict[str, Any]):
    """éŸ³é¢‘è½¬æ–‡æœ¬æ ¸å¿ƒå¤„ç†"""
    start_time = time.time()
    
    # å¤„ç†æ¨¡å‹åç§°
    model_name = options.get("model", "tiny")
    
    # å¦‚æœæ˜¯å®Œæ•´æ¨¡å‹åç§°ï¼ˆå¦‚ Xenova/whisper-tinyï¼‰ï¼Œæå–ç®€å†™
    if "/" in model_name:
        model_name = model_name.split("-")[-1]
    
    # ç¡®ä¿æ¨¡å‹åç§°æœ‰æ•ˆ
    if model_name not in SUPPORTED_MODELS:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}ï¼Œæ”¯æŒçš„æ¨¡å‹æœ‰: {SUPPORTED_MODELS}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(model_name)
    
    # è®¾ç½®è½¬å½•é€‰é¡¹
    transcribe_options = {
        "language": options.get("language", "zh"),
        "task": options.get("subtask", "transcribe"),
        "verbose": False
    }
    
    print(f"ğŸ¤ æ­£åœ¨è½¬å½•éŸ³é¢‘ï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
    print(f"ğŸŒ è¯­è¨€: {transcribe_options['language']}")
    print(f"ğŸ“‹ ä»»åŠ¡: {transcribe_options['task']}")
    
    # æ‰§è¡Œè½¬å½•
    result = model.transcribe(file_path, **transcribe_options)
    
    processing_time = time.time() - start_time
    print(f"âœ… è½¬å½•å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
    
    return result, processing_time

# å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒWhisperæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†æ ¼å¼ï¼Œæ‰€ä»¥ç®€åŒ–å¤„ç†
def process_audio_file(file_path: str) -> str:
    """å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒWhisperæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†æ ¼å¼"""
    print(f"ğŸ”§ æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {file_path}")
    print(f"âœ… ç›´æ¥è¿”å›åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ŒWhisperæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†éŸ³é¢‘æ ¼å¼")
    # åªè¿”å›åŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œè®©Whisperæ¨¡å‹è‡ªåŠ¨å¤„ç†
    return file_path

# å¥åº·æ£€æŸ¥æ¥å£
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "uptime": time.time() - app.startup_time if hasattr(app, 'startup_time') else 0,
        "version": "2.0.0"
    }

# åº”ç”¨å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    app.startup_time = time.time()
    print("ğŸš€ Whisper Python æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
    print("=" * 50)
    print(f"ğŸ“ æœåŠ¡å™¨åœ°å€: http://localhost:3000")
    print(f"ğŸ”— å¥åº·æ£€æŸ¥: http://localhost:3000/health")
    print(f"ğŸ“‹ API æ–‡æ¡£: http://localhost:3000/docs")
    print("=" * 50)
    print("\nğŸ“¡ å¯ç”¨çš„ API ç«¯ç‚¹:")
    print("  GET  /health                    - å¥åº·æ£€æŸ¥")
    print("  GET  /api/models                - è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨")
    print("  GET  /api/languages             - è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨")
    print("  POST /api/transcribe            - å•ä¸ªéŸ³é¢‘è½¬æ–‡æœ¬")
    print("  POST /api/batch-transcribe      - æ‰¹é‡éŸ³é¢‘è½¬æ–‡æœ¬")
    print("  POST /api/transcribe-file       - æœ¬åœ°æ–‡ä»¶è½¬æ–‡æœ¬")
    print("  POST /api/cleanup               - æ¸…ç†æ¨¡å‹èµ„æº")
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("  curl -X POST http://localhost:3000/api/transcribe \\")
    print("    -F \"audio=@your-audio.wav\" \\")
    print("    -F \"model=whisper-tiny\" \\")
    print("    -F \"language=zh\"")
    print("")

# é”™è¯¯å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": str(exc),
            "details": str(exc)
        }
    )

# è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
@app.get("/api/models")
async def get_models():
    try:
        return {
            "success": True,
            "data": SUPPORTED_MODELS
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )

# è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
@app.get("/api/languages")
async def get_languages():
    try:
        return {
            "success": True,
            "data": SUPPORTED_LANGUAGES
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )

# æ¸…ç†æ¨¡å‹èµ„æº
@app.post("/api/cleanup")
async def cleanup_models():
    try:
        # æ¸…ç©ºæ¨¡å‹ç¼“å­˜
        global model_cache
        model_cache.clear()
        print("ğŸ—‘ï¸  æ¨¡å‹èµ„æºå·²æ¸…ç†")
        return {
            "success": True,
            "message": "æ¨¡å‹èµ„æºå·²æ¸…ç†"
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e)
            }
        )

# å•ä¸ªéŸ³é¢‘æ–‡ä»¶è½¬æ–‡æœ¬
@app.post("/api/transcribe")
async def transcribe(
    audio: UploadFile = File(...),
    model: str = Form("tiny"),
    language: str = Form("zh"),
    quantized: str = Form("false"),
    subtask: str = Form("transcribe")
):
    temp_files = []  # ç”¨äºè·Ÿè¸ªä¸´æ—¶æ–‡ä»¶ï¼Œç¡®ä¿æ¸…ç†
    
    try:
        print("\nğŸ¤ æ¥æ”¶åˆ°éŸ³é¢‘è½¬æ–‡æœ¬è¯·æ±‚")
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
        print(f"ğŸ“ ä½¿ç”¨ä¸´æ—¶ç›®å½•: {tempfile.gettempdir()}")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨æ›´å¯é çš„æ–¹å¼
        temp_input = tempfile.NamedTemporaryFile(suffix=os.path.splitext(audio.filename)[1], delete=False)
        input_path = temp_input.name
        temp_input.close()
        temp_files.append(input_path)
        
        # ç¡®ä¿è·¯å¾„æ ¼å¼åœ¨Windowsä¸Šæ­£ç¡®
        input_path = os.path.abspath(input_path)
        print(f"ğŸ“ ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {input_path}")
        
        # å†™å…¥æ–‡ä»¶å†…å®¹
        with open(input_path, "wb") as f:
            content = await audio.read()
            f.write(content)
            print(f"ğŸ’¾ å†™å…¥å†…å®¹å¤§å°: {len(content) / 1024 / 1024:.2f} MB")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸåˆ›å»º
        if not os.path.exists(input_path):
            raise ValueError(f"âŒ ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥: {input_path}")
        
        print(f"ğŸ“ ä¸Šä¼ çš„æ–‡ä»¶: {audio.filename}")
        print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹: {model}")
        print(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
        print(f"ğŸ’¾ ä¸´æ—¶æ–‡ä»¶å¤§å°: {os.path.getsize(input_path) / 1024 / 1024:.2f} MB")
        
        # å¤„ç†éŸ³é¢‘æ–‡ä»¶
        processed_path = process_audio_file(input_path)
        temp_files.append(processed_path)  # æ·»åŠ åˆ°ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        
        # è®¾ç½®è½¬å½•é€‰é¡¹
        options = {
            "model": model,
            "language": language,
            "quantized": quantized.lower() == "true",
            "subtask": subtask
        }
        
        # æ‰§è¡Œè½¬å½•
        result, processing_time = transcribe_audio(processed_path, options)
        
        # æ„å»ºå“åº”ï¼Œå¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„durationé”®
        response = {
            "success": True,
            "data": {
                "text": result["text"],
                "chunks": result["segments"],
                "language": result["language"],
                "duration": result.get("duration", 0),  # ä½¿ç”¨getæ–¹æ³•é¿å…KeyError
                "task": subtask,
                "model": model,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                "processingTime": int(processing_time * 1000),
                "fileInfo": {
                    "originalName": audio.filename,
                    "size": os.path.getsize(input_path),
                    "mimetype": audio.content_type
                }
            }
        }
        
        print(f"âœ… è½¬å½•å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result['text'][:100]}{'...' if len(result['text']) > 100 else ''}")
        
        return response
        
    except Exception as e:
        print(f"âŒ è½¬å½•é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "details": traceback.format_exc()
            }
        )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for file_path in temp_files:
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                    print(f"ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
            except Exception as cleanup_error:
                print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

# æ‰¹é‡éŸ³é¢‘è½¬æ–‡æœ¬
@app.post("/api/batch-transcribe")
async def batch_transcribe(
    audio: List[UploadFile] = File(...),
    model: str = Form("tiny"),
    language: str = Form("zh"),
    quantized: str = Form("false"),
    subtask: str = Form("transcribe")
):
    try:
        print(f"\nğŸ“‚ æ¥æ”¶åˆ°æ‰¹é‡è½¬æ–‡æœ¬è¯·æ±‚ï¼Œå…± {len(audio)} ä¸ªæ–‡ä»¶")
        
        if not audio:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶"
                }
            )
        
        print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹: {model}")
        print(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
        
        # è®¾ç½®è½¬å½•é€‰é¡¹
        options = {
            "model": model,
            "language": language,
            "quantized": quantized.lower() == "true",
            "subtask": subtask
        }
        
        results = []
        total_processing_time = 0
        start_time = time.time()
        
        for i, file in enumerate(audio):
            print(f"\n--- å¤„ç†æ–‡ä»¶ {i+1}/{len(audio)}: {file.filename} ---")
            
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_input = tempfile.NamedTemporaryFile(suffix=os.path.splitext(file.filename)[1], delete=False)
                input_path = temp_input.name
                temp_input.close()
                
                # å†™å…¥æ–‡ä»¶å†…å®¹
                with open(input_path, "wb") as f:
                    f.write(await file.read())
                
                # å¤„ç†éŸ³é¢‘æ–‡ä»¶
                processed_path = process_audio_file(input_path)
                
                # æ‰§è¡Œè½¬å½•
                result, processing_time = transcribe_audio(processed_path, options)
                
                # è®°å½•ç»“æœï¼Œå¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„durationé”®
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "success": True,
                    "text": result["text"],
                    "duration": result.get("duration", 0),  # ä½¿ç”¨getæ–¹æ³•é¿å…KeyError
                    "confidence": sum(seg.get("confidence", 0) for seg in result["segments"]) / len(result["segments"]) if result["segments"] else 0,
                    "language": result["language"],
                    "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "processingTime": int(processing_time * 1000)
                })
                
                total_processing_time += processing_time
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(input_path)
                os.unlink(processed_path)
                
                print(f"âœ… æ–‡ä»¶ {i+1} å¤„ç†æˆåŠŸ")
                
            except Exception as e:
                print(f"âŒ æ–‡ä»¶ {i+1} å¤„ç†å¤±è´¥: {str(e)}")
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "success": False,
                    "error": str(e)
                })
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ„å»ºå“åº”
        response = {
            "success": True,
            "data": {
                "results": results,
                "summary": {
                    "total": len(audio),
                    "successful": sum(1 for r in results if r["success"]),
                    "failed": sum(1 for r in results if not r["success"]),
                    "processingTime": int(total_time * 1000)
                },
                "fileInfo": [
                    {
                        "originalName": file.filename,
                        "size": 0,  # ç”±äºæ–‡ä»¶å·²å¤„ç†ï¼Œæ— æ³•è·å–å‡†ç¡®å¤§å°
                        "mimetype": file.content_type
                    }
                    for file in audio
                ]
            }
        }
        
        print(f"\nâœ… æ‰¹é‡è½¬å½•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        print(f"ğŸ“Š æˆåŠŸ: {response['data']['summary']['successful']}, å¤±è´¥: {response['data']['summary']['failed']}")
        
        return response
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡è½¬å½•é”™è¯¯: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "details": str(e)
            }
        )

# æœ¬åœ°æ–‡ä»¶è½¬æ–‡æœ¬
@app.post("/api/transcribe-file")
async def transcribe_file(
    filePath: str = Body(...),
    options: Dict[str, Any] = Body(default_factory=dict)
):
    try:
        print(f"\nğŸ“ å¤„ç†æœ¬åœ°æ–‡ä»¶: {filePath}")
        
        if not filePath:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "è¯·æä¾›æ–‡ä»¶è·¯å¾„"
                }
            )
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(filePath):
            filePath = os.path.abspath(filePath)
        
        if not os.path.exists(filePath):
            return JSONResponse(
                status_code=404,
                content={
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filePath}"
                }
            )
        
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(filePath) / 1024 / 1024:.2f} MB")
        
        # å¤„ç†éŸ³é¢‘æ–‡ä»¶
        processed_path = process_audio_file(filePath)
        
        # è®¾ç½®é»˜è®¤é€‰é¡¹
        default_options = {
            "model": "tiny",
            "language": "zh",
            "subtask": "transcribe"
        }
        
        # åˆå¹¶é€‰é¡¹
        merged_options = {**default_options, **options}
        
        # æ‰§è¡Œè½¬å½•
        result, processing_time = transcribe_audio(processed_path, merged_options)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(processed_path)
        
        # æ„å»ºå“åº”ï¼Œå¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„durationé”®
        response = {
            "success": True,
            "data": {
                "text": result["text"],
                "chunks": result["segments"],
                "language": result["language"],
                "duration": result.get("duration", 0),  # ä½¿ç”¨getæ–¹æ³•é¿å…KeyError
                "task": merged_options["subtask"],
                "model": merged_options["model"],
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                "processingTime": int(processing_time * 1000),
                "filePath": filePath
            }
        }
        
        print(f"âœ… æœ¬åœ°æ–‡ä»¶è½¬å½•å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result['text'][:100]}{'...' if len(result['text']) > 100 else ''}")
        
        return response
        
    except Exception as e:
        print(f"âŒ æœ¬åœ°æ–‡ä»¶è½¬å½•é”™è¯¯: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "details": str(e)
            }
        )

# 404 å¤„ç†
@app.api_route("{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH"])
async def not_found(path: str):
    return JSONResponse(
        status_code=404,
        content={
            "success": False,
            "error": "æ¥å£ä¸å­˜åœ¨",
            "availableEndpoints": [
                "GET /health",
                "GET /api/models",
                "GET /api/languages",
                "POST /api/transcribe",
                "POST /api/batch-transcribe",
                "POST /api/transcribe-file",
                "POST /api/cleanup"
            ]
        }
    )

# ä¸»å‡½æ•°
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=3000,
        reload=True  # å¼€å‘æ¨¡å¼ä¸‹å¯ç”¨è‡ªåŠ¨é‡è½½
    )
